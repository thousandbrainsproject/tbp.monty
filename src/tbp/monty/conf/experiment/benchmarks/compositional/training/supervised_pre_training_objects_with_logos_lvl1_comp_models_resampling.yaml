# @package _global_
# Two LM stacked pretraining - level 1 compositional with resampling
# Uses goal-state-driven motor policy with smaller saccades for resampling.

defaults:
  - /environment/object_sampler: predefined
  - override /mode: pretrain
  - override /logging: pretrain
  - override /monty: pretraining_two_lm_stacked
  - override /agent_config: two_lm_stacked_habitat
  - override /environment: compositional/objects_with_logos_lvl1

_target_: tbp.monty.frameworks.experiments.pretraining_experiments.MontySupervisedObjectPretrainingExperiment

config:
  n_train_epochs: ${vars.rotations_all_count}
  supervised_lm_ids: ["learning_module_1"]
  min_lms_match: 2
  model_name_or_path: ${path.expanduser:${oc.env:MONTY_MODELS}/pretrained_ycb_v11/supervised_pre_training_logos_after_flat_objects/pretrained/}
  logging:
    output_dir: ${path.expanduser:${oc.env:MONTY_MODELS}/my_trained_models}
    run_name: supervised_pre_training_objects_with_logos_lvl1_comp_models_resampling
  monty_config:
    monty_args:
      num_exploratory_steps: 0
      min_train_steps: 500
    motor_system_config:
      motor_system_class: ${monty.class:tbp.monty.frameworks.models.motor_system.MotorSystem}
      motor_system_args:
        policy_class: ${monty.class:tbp.monty.frameworks.models.motor_policies.InformedPolicy}
        policy_args:
          use_goal_state_driven_actions: true
          action_sampler_class: ${monty.class:tbp.monty.frameworks.actions.action_samplers.ConstantSampler}
          action_sampler_args:
            rotation_degrees: 2.0
  env_interface_class: ${monty.class:tbp.monty.frameworks.environments.embodied_data.InformedEnvironmentInterface}
